{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet101-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**ResNet Training (MNIST)**\n",
        "\n"
      ],
      "metadata": {
        "id": "F_HGybCmtOA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1. Import Library & Define Resnet model**"
      ],
      "metadata": {
        "id": "yJs9RTVyuoE1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YUnNEefre_Vv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "from collections import OrderedDict\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class Conv2dAuto(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
        "        \n",
        "\n",
        "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
        "        self.blocks = nn.Identity()\n",
        "        self.shortcut = nn.Identity()   \n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
        "        x = self.blocks(x)\n",
        "        x += residual\n",
        "        return x\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.out_channels\n",
        "    \n",
        "\n",
        "\n",
        "class ResNetResidualBlock(ResidualBlock):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels)\n",
        "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
        "        self.shortcut = nn.Sequential(OrderedDict(\n",
        "        {\n",
        "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                      stride=self.downsampling, bias=False),\n",
        "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
        "            \n",
        "        })) if self.should_apply_shortcut else None\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def expanded_channels(self):\n",
        "        return self.out_channels * self.expansion\n",
        "    \n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.expanded_channels\n",
        "\n",
        "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
        "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
        "                          'bn': nn.BatchNorm2d(out_channels) }))\n",
        "\n",
        "class ResNetBasicBlock(ResNetResidualBlock):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
        "            activation(),\n",
        "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
        "        )\n",
        "        \n",
        "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
        "             activation(),\n",
        "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
        "             activation(),\n",
        "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
        "        )\n",
        "        \n",
        "class ResNetLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
        "        downsampling = 2 if in_channels != out_channels else 1\n",
        "        \n",
        "        self.blocks = nn.Sequential(\n",
        "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
        "            *[block(out_channels * block.expansion, \n",
        "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return x\n",
        "    \n",
        "class ResNetEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet encoder composed by increasing different layers with increasing features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
        "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.blocks_sizes = blocks_sizes\n",
        "        \n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
        "            activation(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        \n",
        "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
        "        self.blocks = nn.ModuleList([ \n",
        "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
        "                        block=block,  *args, **kwargs),\n",
        "            *[ResNetLayer(in_channels * block.expansion, \n",
        "                          out_channels, n=n, activation=activation, \n",
        "                          block=block, *args, **kwargs) \n",
        "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
        "        ])\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.gate(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "class ResnetDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
        "    correct class by using a fully connected layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, n_classes):\n",
        "        super().__init__()\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.decoder = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
        "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "def resnet18(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
        "\n",
        "def resnet34(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
        "\n",
        "def resnet50(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
        "\n",
        "def resnet101(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
        "\n",
        "def resnet152(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2. Download MNIST**"
      ],
      "metadata": {
        "id": "uCr3Xy1Lu7l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download MNIST DATASET\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0y64sMAu8F5",
        "outputId": "0c492518-443e-42ac-baad-9e21a4720c0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3. CUDA setting & Define Train,Test function**"
      ],
      "metadata": {
        "id": "dIoN4DWTvOrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu setting & define Training function\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "net = resnet101(1,10)           #resnet152 선언\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "learning_rate = 0.1\n",
        "file_name = 'resnet101_mnist.pt'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        benign_outputs = net(inputs)\n",
        "        loss = criterion(benign_outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = benign_outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nCurrent batch:', str(batch_idx))\n",
        "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
        "            print('Current benign train loss:', loss.item())\n",
        "\n",
        "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
        "    print('Total benign train loss:', train_loss)\n",
        "    total_accuracy = 100. * correct / total;\n",
        "\n",
        "    return total_accuracy , train_loss\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('\\nTest accuarcy:', 100. * correct / total)\n",
        "    print('Test average loss:', loss / total)\n",
        "    total_accuracy = 100. * correct / total;\n",
        "    test_loss = loss / total\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/' + file_name)\n",
        "    print('Model Saved!')\n",
        "\n",
        "    return total_accuracy , test_loss\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "y0u4Fi9CvQYj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4. Run Training & Save log**"
      ],
      "metadata": {
        "id": "nXgOgZRIvo6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in range(0, 200):\n",
        "log_train_total_accuracy =[]\n",
        "log_train_total_loss = []\n",
        "log_test_total_accuracy =[]\n",
        "log_test_total_loss =[]\n",
        "\n",
        "\n",
        "for epoch in range(0, 20):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_total_accuracy, train_total_loss = train(epoch)\n",
        "    test_total_accuracy, test_total_loss = test(epoch)\n",
        "    log_train_total_accuracy.append(train_total_accuracy)\n",
        "    log_train_total_loss.append(train_total_loss)\n",
        "    log_test_total_accuracy.append(test_total_accuracy)\n",
        "    log_test_total_loss.append(test_total_loss)"
      ],
      "metadata": {
        "id": "ECJO1DkTvpOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68b0cd8-c532-43ae-e7d3-5e27bd743c6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.1328125\n",
            "Current benign train loss: 2.7606966495513916\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.1875\n",
            "Current benign train loss: 12.920282363891602\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.3828125\n",
            "Current benign train loss: 2.1478652954101562\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.5546875\n",
            "Current benign train loss: 1.398099660873413\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.6171875\n",
            "Current benign train loss: 1.1567312479019165\n",
            "\n",
            "Total benign train accuarcy: 38.34166666666667\n",
            "Total benign train loss: 5302.4038438797\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "\n",
            "Test accuarcy: 75.92\n",
            "Test average loss: 0.0071301620662212375\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.6328125\n",
            "Current benign train loss: 1.0831804275512695\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.8515625\n",
            "Current benign train loss: 0.49353688955307007\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.27881476283073425\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.8671875\n",
            "Current benign train loss: 0.3719612956047058\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.8515625\n",
            "Current benign train loss: 0.5327488780021667\n",
            "\n",
            "Total benign train accuarcy: 87.06333333333333\n",
            "Total benign train loss: 197.83100228756666\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Test accuarcy: 92.11\n",
            "Test average loss: 0.0024217152079567313\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.11424718797206879\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.21247774362564087\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9140625\n",
            "Current benign train loss: 0.23581993579864502\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.20091699063777924\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.14829757809638977\n",
            "\n",
            "Total benign train accuarcy: 93.53\n",
            "Total benign train loss: 98.89740809425712\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Test accuarcy: 94.57\n",
            "Test average loss: 0.0017081010894849896\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.11683615297079086\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.19629134237766266\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.16627028584480286\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.19120532274246216\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.1451258659362793\n",
            "\n",
            "Total benign train accuarcy: 95.03333333333333\n",
            "Total benign train loss: 76.25094896182418\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Test accuarcy: 96.81\n",
            "Test average loss: 0.0010467279852833598\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.10618159919977188\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.0882960706949234\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.07710066437721252\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.921875\n",
            "Current benign train loss: 0.12206193804740906\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9296875\n",
            "Current benign train loss: 0.20949923992156982\n",
            "\n",
            "Total benign train accuarcy: 96.00166666666667\n",
            "Total benign train loss: 60.59837918356061\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Test accuarcy: 97.2\n",
            "Test average loss: 0.0009153448928613216\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.14379310607910156\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.05596381798386574\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9375\n",
            "Current benign train loss: 0.19089271128177643\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.13788437843322754\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9453125\n",
            "Current benign train loss: 0.16128677129745483\n",
            "\n",
            "Total benign train accuarcy: 96.69666666666667\n",
            "Total benign train loss: 50.48917043674737\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Test accuarcy: 97.4\n",
            "Test average loss: 0.0008127956963144243\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.08308394998311996\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.11109073460102081\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.10233993828296661\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.110029436647892\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.07010972499847412\n",
            "\n",
            "Total benign train accuarcy: 97.02833333333334\n",
            "Total benign train loss: 44.867539562284946\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Test accuarcy: 97.28\n",
            "Test average loss: 0.0008928583212895319\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.07482059299945831\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.08621911704540253\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.0606425404548645\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.953125\n",
            "Current benign train loss: 0.14519691467285156\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.15150873363018036\n",
            "\n",
            "Total benign train accuarcy: 97.525\n",
            "Total benign train loss: 37.664829429239035\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Test accuarcy: 97.83\n",
            "Test average loss: 0.0006564713455503807\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.10565820336341858\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.035081952810287476\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.07102704793214798\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.06422626227140427\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.08841926604509354\n",
            "\n",
            "Total benign train accuarcy: 97.73666666666666\n",
            "Total benign train loss: 33.60465031582862\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Test accuarcy: 98.24\n",
            "Test average loss: 0.0005494606201827992\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.05665435642004013\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.04188207909464836\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9609375\n",
            "Current benign train loss: 0.10835709422826767\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.06841599941253662\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.09328397363424301\n",
            "\n",
            "Total benign train accuarcy: 97.95166666666667\n",
            "Total benign train loss: 29.70749614480883\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Test accuarcy: 97.73\n",
            "Test average loss: 0.0007206406257813797\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.02843375876545906\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.050134945660829544\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.02663535252213478\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.06992034614086151\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.96875\n",
            "Current benign train loss: 0.09515231102705002\n",
            "\n",
            "Total benign train accuarcy: 98.21666666666667\n",
            "Total benign train loss: 26.588324212934822\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Test accuarcy: 98.25\n",
            "Test average loss: 0.0005590926959586795\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.05830959975719452\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.058714717626571655\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.03076954372227192\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.0722804144024849\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.08814132213592529\n",
            "\n",
            "Total benign train accuarcy: 98.41333333333333\n",
            "Total benign train loss: 23.852846570312977\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "\n",
            "Test accuarcy: 98.28\n",
            "Test average loss: 0.000520625971670961\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.02421337552368641\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.03998836874961853\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.015436041168868542\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.05678996816277504\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.029940379783511162\n",
            "\n",
            "Total benign train accuarcy: 98.51\n",
            "Total benign train loss: 22.021529694553465\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "\n",
            "Test accuarcy: 98.5\n",
            "Test average loss: 0.00042954132220038445\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.023987863212823868\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.052528560161590576\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.07237885892391205\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.025719624012708664\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.0146879181265831\n",
            "\n",
            "Total benign train accuarcy: 98.575\n",
            "Total benign train loss: 20.793362079188228\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "\n",
            "Test accuarcy: 98.37\n",
            "Test average loss: 0.0005030691886960994\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.04255588725209236\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.024171002209186554\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.12426944077014923\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.02064281888306141\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.027148853987455368\n",
            "\n",
            "Total benign train accuarcy: 98.69666666666667\n",
            "Total benign train loss: 19.266022718744352\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "\n",
            "Test accuarcy: 98.73\n",
            "Test average loss: 0.0003749300215567928\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.030335653573274612\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.03705262020230293\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.04285634681582451\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.08929771929979324\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.010303592309355736\n",
            "\n",
            "Total benign train accuarcy: 98.81166666666667\n",
            "Total benign train loss: 18.081652730237693\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "\n",
            "Test accuarcy: 98.47\n",
            "Test average loss: 0.0004411756145476829\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.04249536246061325\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.010355288162827492\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.025453494861721992\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.006936343852430582\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.004191301763057709\n",
            "\n",
            "Total benign train accuarcy: 98.76\n",
            "Total benign train loss: 18.09888614830561\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "\n",
            "Test accuarcy: 98.42\n",
            "Test average loss: 0.0004755804801767226\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.04172299802303314\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.022535016760230064\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.016082465648651123\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.049355633556842804\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.013147708959877491\n",
            "\n",
            "Total benign train accuarcy: 98.89166666666667\n",
            "Total benign train loss: 16.481117418035865\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "\n",
            "Test accuarcy: 98.72\n",
            "Test average loss: 0.000368754012385034\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.024315332993865013\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.026519866660237312\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.012980341911315918\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.014107403345406055\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.041141290217638016\n",
            "\n",
            "Total benign train accuarcy: 98.925\n",
            "Total benign train loss: 15.760608598822728\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "\n",
            "Test accuarcy: 98.75\n",
            "Test average loss: 0.0004013338685268536\n",
            "Model Saved!\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current benign train accuracy: 1.0\n",
            "Current benign train loss: 0.005933068227022886\n",
            "\n",
            "Current batch: 100\n",
            "Current benign train accuracy: 0.9921875\n",
            "Current benign train loss: 0.03658793866634369\n",
            "\n",
            "Current batch: 200\n",
            "Current benign train accuracy: 0.9765625\n",
            "Current benign train loss: 0.07195999473333359\n",
            "\n",
            "Current batch: 300\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.049577273428440094\n",
            "\n",
            "Current batch: 400\n",
            "Current benign train accuracy: 0.984375\n",
            "Current benign train loss: 0.04411568120121956\n",
            "\n",
            "Total benign train accuarcy: 98.945\n",
            "Total benign train loss: 16.18617395788897\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "\n",
            "Test accuarcy: 98.37\n",
            "Test average loss: 0.0005147263069520705\n",
            "Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5. Plotting Train Accuracy & Loss**"
      ],
      "metadata": {
        "id": "02KWRk8gwDuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch =[]\n",
        "\n",
        "for i , loss in enumerate(log_test_total_loss):\n",
        "  epoch.append(i+1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('log_train_accuracy')\n",
        "plt.plot(epoch , log_train_total_accuracy)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('train_accuracy')\n",
        "plt.show()  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "9K8Tpz79wQfY",
        "outputId": "74de7e29-7932-4c95-e0be-e5cf008556d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('log_train_loss')\n",
        "plt.plot(epoch , log_train_total_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('train_loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aDHZdUejwYuc",
        "outputId": "4a6f15a5-fdc7-4bb3-8e10-3648678acf87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**6. Plotting Test Accuracy & Loss**"
      ],
      "metadata": {
        "id": "kIHe2WBwwe0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('log_test_accuracy')\n",
        "plt.plot(epoch , log_test_total_accuracy)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('test_accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "r8VyAgG9wsmj",
        "outputId": "bd27ee5d-abe6-4526-be0c-6ba7dd0c16f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('log_test_loss')\n",
        "plt.plot(epoch , log_test_total_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('test_loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ynng-93MlZC_",
        "outputId": "3b574127-7737-4e2a-9f28-e3edaf844634"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7. Print Result**"
      ],
      "metadata": {
        "id": "yS1fhsxpxAGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(log_train_total_accuracy)\n",
        "print(log_train_total_loss) \n",
        "print(log_test_total_accuracy)\n",
        "print(log_test_total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BEdftZQpUNb",
        "outputId": "7b61a418-9e47-4273-ed39-f4b40bcc5da1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38.34166666666667, 87.06333333333333, 93.53, 95.03333333333333, 96.00166666666667, 96.69666666666667, 97.02833333333334, 97.525, 97.73666666666666, 97.95166666666667, 98.21666666666667, 98.41333333333333, 98.51, 98.575, 98.69666666666667, 98.81166666666667, 98.76, 98.89166666666667, 98.925, 98.945]\n",
            "[5302.4038438797, 197.83100228756666, 98.89740809425712, 76.25094896182418, 60.59837918356061, 50.48917043674737, 44.867539562284946, 37.664829429239035, 33.60465031582862, 29.70749614480883, 26.588324212934822, 23.852846570312977, 22.021529694553465, 20.793362079188228, 19.266022718744352, 18.081652730237693, 18.09888614830561, 16.481117418035865, 15.760608598822728, 16.18617395788897]\n",
            "[75.92, 92.11, 94.57, 96.81, 97.2, 97.4, 97.28, 97.83, 98.24, 97.73, 98.25, 98.28, 98.5, 98.37, 98.73, 98.47, 98.42, 98.72, 98.75, 98.37]\n",
            "[0.0071301620662212375, 0.0024217152079567313, 0.0017081010894849896, 0.0010467279852833598, 0.0009153448928613216, 0.0008127956963144243, 0.0008928583212895319, 0.0006564713455503807, 0.0005494606201827992, 0.0007206406257813797, 0.0005590926959586795, 0.000520625971670961, 0.00042954132220038445, 0.0005030691886960994, 0.0003749300215567928, 0.0004411756145476829, 0.0004755804801767226, 0.000368754012385034, 0.0004013338685268536, 0.0005147263069520705]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**8. Model Summary**"
      ],
      "metadata": {
        "id": "-3oJny8-xLSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = resnet101(1, 10)\n",
        "summary(model.cuda(), (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlLn0Csop0Dx",
        "outputId": "fd4708cc-f5af-4740-feff-097a35a897d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 14, 14]           3,136\n",
            "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
            "              ReLU-3           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Conv2d-5            [-1, 256, 7, 7]          16,384\n",
            "       BatchNorm2d-6            [-1, 256, 7, 7]             512\n",
            "        Conv2dAuto-7             [-1, 64, 7, 7]           4,096\n",
            "       BatchNorm2d-8             [-1, 64, 7, 7]             128\n",
            "              ReLU-9             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-10             [-1, 64, 7, 7]          36,864\n",
            "      BatchNorm2d-11             [-1, 64, 7, 7]             128\n",
            "             ReLU-12             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-13            [-1, 256, 7, 7]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 7, 7]             512\n",
            "ResNetBottleNeckBlock-15            [-1, 256, 7, 7]               0\n",
            "       Conv2dAuto-16             [-1, 64, 7, 7]          16,384\n",
            "      BatchNorm2d-17             [-1, 64, 7, 7]             128\n",
            "             ReLU-18             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-19             [-1, 64, 7, 7]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 7, 7]             128\n",
            "             ReLU-21             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-22            [-1, 256, 7, 7]          16,384\n",
            "      BatchNorm2d-23            [-1, 256, 7, 7]             512\n",
            "ResNetBottleNeckBlock-24            [-1, 256, 7, 7]               0\n",
            "       Conv2dAuto-25             [-1, 64, 7, 7]          16,384\n",
            "      BatchNorm2d-26             [-1, 64, 7, 7]             128\n",
            "             ReLU-27             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-28             [-1, 64, 7, 7]          36,864\n",
            "      BatchNorm2d-29             [-1, 64, 7, 7]             128\n",
            "             ReLU-30             [-1, 64, 7, 7]               0\n",
            "       Conv2dAuto-31            [-1, 256, 7, 7]          16,384\n",
            "      BatchNorm2d-32            [-1, 256, 7, 7]             512\n",
            "ResNetBottleNeckBlock-33            [-1, 256, 7, 7]               0\n",
            "      ResNetLayer-34            [-1, 256, 7, 7]               0\n",
            "           Conv2d-35            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-36            [-1, 512, 4, 4]           1,024\n",
            "       Conv2dAuto-37            [-1, 128, 7, 7]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 7, 7]             256\n",
            "             ReLU-39            [-1, 128, 7, 7]               0\n",
            "       Conv2dAuto-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "ResNetBottleNeckBlock-45            [-1, 512, 4, 4]               0\n",
            "       Conv2dAuto-46            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-47            [-1, 128, 4, 4]             256\n",
            "             ReLU-48            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-49            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-52            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-53            [-1, 512, 4, 4]           1,024\n",
            "ResNetBottleNeckBlock-54            [-1, 512, 4, 4]               0\n",
            "       Conv2dAuto-55            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 128, 4, 4]             256\n",
            "             ReLU-57            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-58            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-59            [-1, 128, 4, 4]             256\n",
            "             ReLU-60            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-61            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-62            [-1, 512, 4, 4]           1,024\n",
            "ResNetBottleNeckBlock-63            [-1, 512, 4, 4]               0\n",
            "       Conv2dAuto-64            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-65            [-1, 128, 4, 4]             256\n",
            "             ReLU-66            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-67            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-68            [-1, 128, 4, 4]             256\n",
            "             ReLU-69            [-1, 128, 4, 4]               0\n",
            "       Conv2dAuto-70            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-71            [-1, 512, 4, 4]           1,024\n",
            "ResNetBottleNeckBlock-72            [-1, 512, 4, 4]               0\n",
            "      ResNetLayer-73            [-1, 512, 4, 4]               0\n",
            "           Conv2d-74           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-75           [-1, 1024, 2, 2]           2,048\n",
            "       Conv2dAuto-76            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-77            [-1, 256, 4, 4]             512\n",
            "             ReLU-78            [-1, 256, 4, 4]               0\n",
            "       Conv2dAuto-79            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
            "             ReLU-81            [-1, 256, 2, 2]               0\n",
            "       Conv2dAuto-82           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-83           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-84           [-1, 1024, 2, 2]               0\n",
            "       Conv2dAuto-85            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-86            [-1, 256, 2, 2]             512\n",
            "             ReLU-87            [-1, 256, 2, 2]               0\n",
            "       Conv2dAuto-88            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-89            [-1, 256, 2, 2]             512\n",
            "             ReLU-90            [-1, 256, 2, 2]               0\n",
            "       Conv2dAuto-91           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-92           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-93           [-1, 1024, 2, 2]               0\n",
            "       Conv2dAuto-94            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "       Conv2dAuto-97            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-98            [-1, 256, 2, 2]             512\n",
            "             ReLU-99            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-100           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-101           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-102           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-103            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-104            [-1, 256, 2, 2]             512\n",
            "            ReLU-105            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-106            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-107            [-1, 256, 2, 2]             512\n",
            "            ReLU-108            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-109           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-110           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-111           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-112            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-113            [-1, 256, 2, 2]             512\n",
            "            ReLU-114            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-115            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-116            [-1, 256, 2, 2]             512\n",
            "            ReLU-117            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-118           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-119           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-120           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-129           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-130            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-131            [-1, 256, 2, 2]             512\n",
            "            ReLU-132            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-133            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-134            [-1, 256, 2, 2]             512\n",
            "            ReLU-135            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-136           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-137           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-138           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-139            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-140            [-1, 256, 2, 2]             512\n",
            "            ReLU-141            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-142            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-143            [-1, 256, 2, 2]             512\n",
            "            ReLU-144            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-145           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-146           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-147           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-148            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-149            [-1, 256, 2, 2]             512\n",
            "            ReLU-150            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-151            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-152            [-1, 256, 2, 2]             512\n",
            "            ReLU-153            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-154           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-155           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-156           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-157            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-158            [-1, 256, 2, 2]             512\n",
            "            ReLU-159            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-160            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-161            [-1, 256, 2, 2]             512\n",
            "            ReLU-162            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-163           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-164           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-165           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-166            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-167            [-1, 256, 2, 2]             512\n",
            "            ReLU-168            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-169            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-170            [-1, 256, 2, 2]             512\n",
            "            ReLU-171            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-172           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-173           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-174           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-175            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-176            [-1, 256, 2, 2]             512\n",
            "            ReLU-177            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-178            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-179            [-1, 256, 2, 2]             512\n",
            "            ReLU-180            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-181           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-182           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-183           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-184            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-185            [-1, 256, 2, 2]             512\n",
            "            ReLU-186            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-187            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-188            [-1, 256, 2, 2]             512\n",
            "            ReLU-189            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-190           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-191           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-192           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-193            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-194            [-1, 256, 2, 2]             512\n",
            "            ReLU-195            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-196            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-197            [-1, 256, 2, 2]             512\n",
            "            ReLU-198            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-199           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-200           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-201           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-202            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-203            [-1, 256, 2, 2]             512\n",
            "            ReLU-204            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-205            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-206            [-1, 256, 2, 2]             512\n",
            "            ReLU-207            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-208           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-209           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-210           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-211            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-212            [-1, 256, 2, 2]             512\n",
            "            ReLU-213            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-214            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-215            [-1, 256, 2, 2]             512\n",
            "            ReLU-216            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-217           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-218           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-219           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-220            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-221            [-1, 256, 2, 2]             512\n",
            "            ReLU-222            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-223            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-224            [-1, 256, 2, 2]             512\n",
            "            ReLU-225            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-226           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-227           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-228           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-229            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-230            [-1, 256, 2, 2]             512\n",
            "            ReLU-231            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-232            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-233            [-1, 256, 2, 2]             512\n",
            "            ReLU-234            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-235           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-236           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-237           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-238            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-239            [-1, 256, 2, 2]             512\n",
            "            ReLU-240            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-241            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-242            [-1, 256, 2, 2]             512\n",
            "            ReLU-243            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-244           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-245           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-246           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-247            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-248            [-1, 256, 2, 2]             512\n",
            "            ReLU-249            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-250            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-251            [-1, 256, 2, 2]             512\n",
            "            ReLU-252            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-253           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-254           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-255           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-256            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-257            [-1, 256, 2, 2]             512\n",
            "            ReLU-258            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-259            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-260            [-1, 256, 2, 2]             512\n",
            "            ReLU-261            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-262           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-263           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-264           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-265            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-266            [-1, 256, 2, 2]             512\n",
            "            ReLU-267            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-268            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-269            [-1, 256, 2, 2]             512\n",
            "            ReLU-270            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-271           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-272           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-273           [-1, 1024, 2, 2]               0\n",
            "      Conv2dAuto-274            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-275            [-1, 256, 2, 2]             512\n",
            "            ReLU-276            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-277            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-278            [-1, 256, 2, 2]             512\n",
            "            ReLU-279            [-1, 256, 2, 2]               0\n",
            "      Conv2dAuto-280           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-281           [-1, 1024, 2, 2]           2,048\n",
            "ResNetBottleNeckBlock-282           [-1, 1024, 2, 2]               0\n",
            "     ResNetLayer-283           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-284           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-285           [-1, 2048, 1, 1]           4,096\n",
            "      Conv2dAuto-286            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-287            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-288            [-1, 512, 2, 2]               0\n",
            "      Conv2dAuto-289            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-290            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-291            [-1, 512, 1, 1]               0\n",
            "      Conv2dAuto-292           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-293           [-1, 2048, 1, 1]           4,096\n",
            "ResNetBottleNeckBlock-294           [-1, 2048, 1, 1]               0\n",
            "      Conv2dAuto-295            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-296            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-297            [-1, 512, 1, 1]               0\n",
            "      Conv2dAuto-298            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-299            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-300            [-1, 512, 1, 1]               0\n",
            "      Conv2dAuto-301           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-302           [-1, 2048, 1, 1]           4,096\n",
            "ResNetBottleNeckBlock-303           [-1, 2048, 1, 1]               0\n",
            "      Conv2dAuto-304            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-305            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-306            [-1, 512, 1, 1]               0\n",
            "      Conv2dAuto-307            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-308            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-309            [-1, 512, 1, 1]               0\n",
            "      Conv2dAuto-310           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-311           [-1, 2048, 1, 1]           4,096\n",
            "ResNetBottleNeckBlock-312           [-1, 2048, 1, 1]               0\n",
            "     ResNetLayer-313           [-1, 2048, 1, 1]               0\n",
            "   ResNetEncoder-314           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-315           [-1, 2048, 1, 1]               0\n",
            "          Linear-316                   [-1, 10]          20,490\n",
            "   ResnetDecoder-317                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 42,514,378\n",
            "Trainable params: 42,514,378\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 7.02\n",
            "Params size (MB): 162.18\n",
            "Estimated Total Size (MB): 169.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}